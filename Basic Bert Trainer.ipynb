{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f086341",
   "metadata": {},
   "source": [
    "# BERT Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48431418",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37eb96f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e84e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65764e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a3244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ce31b",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77dafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'data/bbc-text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a0ef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee55141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['category']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115fa31",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5330aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   146,  1209,  2824,  2508, 26173,  3568,   102,     0,     0]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['token_type_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36db3eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] I will watch Memento tonight [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65d5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a92b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'business':0,\n",
    "          'entertainment':1,\n",
    "          'sport':2,\n",
    "          'tech':3,\n",
    "          'politics':4\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6d697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780 222 223\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d828dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e4c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7211ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [1:02:51<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.742                 | Train Accuracy:  0.388                 | Val Loss:  0.554                 | Val Accuracy:  0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [1:02:05<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.319                 | Train Accuracy:  0.907                 | Val Loss:  0.165                 | Val Accuracy:  0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [56:49<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.131                 | Train Accuracy:  0.976                 | Val Loss:  0.084                 | Val Accuracy:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [55:21<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.073                 | Train Accuracy:  0.987                 | Val Loss:  0.051                 | Val Accuracy:  0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 890/890 [1:04:50<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.043                 | Train Accuracy:  0.996                 | Val Loss:  0.036                 | Val Accuracy:  0.995\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ba0b8e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(3)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(4)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m    \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m    \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(5)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(6)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m    \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m    \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(7)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      5 \u001b[0;31m    \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 7 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(10)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      8 \u001b[0;31m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 10 \u001b[0;31m    \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(11)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m    \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(13)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     11 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m              \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m              \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(14)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m              \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m              \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m              \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> test_input, test_label\n",
      "({'input_ids': tensor([[[  101, 15046, 26315,  ...,  1602,  4569,   102]],\n",
      "\n",
      "        [[  101,   171, 20293,  ...,     0,     0,     0]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]])}, tensor([4, 4]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(15)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m              \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m              \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m              \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m              \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> test_label\n",
      "tensor([4, 4])\n",
      "ipdb> device\n",
      "device(type='cpu')\n",
      "ipdb> input_id\n",
      "*** NameError: name 'input_id' is not defined\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(16)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m              \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m              \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m              \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m              \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m              \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(17)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m              \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m              \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m              \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m              \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m              \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input_id\n",
      "tensor([[  101, 15046, 26315,  ...,  1602,  4569,   102],\n",
      "        [  101,   171, 20293,  ...,     0,     0,     0]])\n",
      "ipdb> mask\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]])\n",
      "ipdb> model(input_id, mask)\n",
      "tensor([[0.7542, 0.0000, 0.0000, 0.0000, 4.3362],\n",
      "        [0.5700, 0.0917, 0.0000, 0.2118, 5.0630]])\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(18)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m              \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m              \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m              \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m              \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/ipykernel_9562/3190260024.py\u001b[0m(19)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     17 \u001b[0;31m              \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m              \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 19 \u001b[0;31m              \u001b[0mtotal_acc_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Accuracy: {total_acc_test / len(test_data): .3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> acc\n",
      "2\n",
      "ipdb> c\n",
      "Test Accuracy:  0.987\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "    test = Dataset(test_data)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "              output = model(input_id, mask)\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a0159",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab60e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'models/basic_bert.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f67ec1a",
   "metadata": {},
   "source": [
    "### Loading from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41379c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/basic_bert.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53a0134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>politics</td>\n",
       "      <td>chancellor rallies labour voters gordon brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair to face trust issue head on tony blair s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>business</td>\n",
       "      <td>beijingers fume over parking fees choking traf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>politics</td>\n",
       "      <td>blair rejects iraq advice calls tony blair has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>business</td>\n",
       "      <td>turkey knocks six zeros off lira turkey is to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>sport</td>\n",
       "      <td>a november to remember last saturday  one news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>sport</td>\n",
       "      <td>african double in edinburgh world 5000m champi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>tech</td>\n",
       "      <td>what price for  trusted pc security   you can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>sport</td>\n",
       "      <td>o driscoll/gregan lead aid stars ireland s bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>tech</td>\n",
       "      <td>new year s texting breaks record a mobile phon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "1154  politics  chancellor rallies labour voters gordon brown ...\n",
       "207   politics  blair to face trust issue head on tony blair s...\n",
       "2219  business  beijingers fume over parking fees choking traf...\n",
       "1682  politics  blair rejects iraq advice calls tony blair has...\n",
       "1122  business  turkey knocks six zeros off lira turkey is to ...\n",
       "...        ...                                                ...\n",
       "1638     sport  a november to remember last saturday  one news...\n",
       "1095     sport  african double in edinburgh world 5000m champi...\n",
       "1130      tech  what price for  trusted pc security   you can ...\n",
       "1294     sport  o driscoll/gregan lead aid stars ireland s bri...\n",
       "860       tech  new year s texting breaks record a mobile phon...\n",
       "\n",
       "[223 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c72b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(some_text, model):\n",
    "    bert_input = tokenizer(some_text, padding='max_length', max_length = 10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mask = bert_input['attention_mask'].to(device)\n",
    "        input_id = bert_input['input_ids'].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "    \n",
    "    print(output.argmax(dim=1))\n",
    "    return output.argmax(dim=1), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9dc6ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "result, full_op = get_prediction(df.loc[5][1], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f8b76fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6994, 0.0000, 0.0000, 0.4855, 0.0693]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb3c718b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category                                                sport\n",
       "text        yeading face newcastle in fa cup premiership s...\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "73e40518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business {0: 'business', 1: 'entertainment', 2: 'sport', 3: 'tech', 4: 'politics'}\n"
     ]
    }
   ],
   "source": [
    "reverse_map = {v:k for k, v in labels.items()}\n",
    "print(reverse_map[int(result)], reverse_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8a6d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics \n",
      " howard hits back at mongrel jibe michael howard has said a claim by peter hain that the tory leader is acting like an  attack mongrel  shows labour is  rattled  by the opposition.  in an upbeat speech to his party s spring conference in brighton  he said labour s campaigning tactics proved the tories were hitting home. mr hain made the claim about tory tactics in the anti-terror bill debate.  something tells me that someone  somewhere out there is just a little bit rattled   mr howard said. mr hain  leader of the commons  told bbc radio four s today programme that mr howard s stance on the government s anti-terrorism legislation was putting the country at risk. he then accused the tory leader of behaving like an  attack mongrel  and  playing opposition for opposition sake .  mr howard told his party that labour would  do anything  say anything  claim anything to cling on to office at all costs .  so far this year they have compared me to fagin  to shylock and to a flying pig. this morning peter hain even called me a mongrel.  i don t know about you  but something tells me that someone  somewhere out there is just a little bit rattled.  environment secretary margaret beckett rejected mr howard s comment  telling radio 4 s pm programme that labour was not  rattled .  we have a very real duty to try to get people to focus on michael howard s record  what the proposals are that he is trying to put forward to the country and also the many examples we are seeing now of what we believe is really poor judgement on his behalf.   mr howard said tory policies on schools  taxes  immigration and crime were striking a chord with voters.   since the beginning of this year - election year - we ve been making the political weather   he told the party conference. mr howard denied he had been  playing politics  by raising the case of margaret dixon  whose operation had been cancelled seven times  which grabbed headlines for the party two weeks ago. and he hit back at labour claims he had used mrs dixon as a  human shield .  she s not a human shield mr blair  she s a human being.  mr howard said his party plans for immigration quotas  which have also been the focus of much media coverage  were not  racist  - just  common sense .  he pledged cleaner hospitals and better school discipline  with a promise to get rid of  political correctness  in the national curriculum and give everyone to the same chance of a  decent  state education as he had.  i come from an ordinary family. if the teenage michael howard were applying to cambridge today  gordon brown would love me.   and he stressed his party s commitment to cut taxes and red tape and increase the basic state pension in line with earnings. he finished with a personal appeal to party activists to go out and win the next election.  one day you will be able to tell your children and grandchildren as i will tell mine   i was there. i did my bit. i played my part. i helped to win that famous election - the election that transformed our country for the better .  labour election co-ordinator alan milburn said:  michael howard s speech today confirms what we have always said - that his only strategy is opportunism but he has no forward vision for the country. in reference to the appearance of mr howard s family on the conference stage with him  mr milburn said:  michael howard is perfectly entitled to pose with his family today.  but it is the hard working families across britain that will be damaged by his plan to cut £35bn from public spending.\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[5][0], \"\\n\", df.loc[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0976110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
